{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import keras\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.python.keras.optimizers import Adam,RMSprop\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D,BatchNormalization,Dropout,Conv2D,MaxPool2D,AveragePooling2D,ReLU\nfrom tensorflow.python.keras.activations import tanh,softmax\nimport tensorflow as tf\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.utils import plot_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.models import Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/'\nval_dir = '../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n                                   zoom_range=0.3,\n                                   horizontal_flip=True)\n\ntraining_set = train_datagen.flow_from_directory(train_dir,\n                                                batch_size=128,\n                                                target_size=(128,128),\n                                                shuffle=True,\n                                                color_mode='rgb',\n                                                class_mode='categorical')\n\nval_datagen = ImageDataGenerator(rescale=1./255)\nval_set = val_datagen.flow_from_directory(val_dir,\n                                                batch_size=128,\n                                                target_size=(128,128),\n                                                shuffle=True,\n                                                color_mode='rgb',\n                                                class_mode='categorical')\n'''testx=[]\ntesty=[]\nfor i in range(500):\n    a,b=val_set.next()\n    testx.append(a)\n    testy.append(b)\ntestx=np.asarray(testx)\ntesty=np.asarray(testy)\nprint(testx.shape)\nprint(testy.shape)'''\n'''test_set=[]\ntest_labels=[]\nfor k in os.listdir(test_dir):\n    img=cv2.imread(test_dir+k)\n    img=cv2.resize(img,(128,128))\n    test_set.append(img)\n    l=k.split('.')\n    test_labels.append(l[0][:-1])\ntest_set=np.asarray(test_set)/.255\nprint(test_set.shape)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.densenet import DenseNet201, DenseNet121","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model2 = DenseNet201(\n            include_top=False,\n            weights='imagenet',\n            input_shape=(128,128,3),\n            pooling='max')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model2 = Sequential([\n        base_model2,\n        Dense(128, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.2),\n        Dense(64, activation='relu'),\n        Dropout(0.3),\n        Dense(38, activation='softmax')\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential([\n    Conv2D(32,kernel_size=(2,2),padding='same',input_shape=(128,128,3)),\n    Conv2D(64,kernel_size=(2,2)),\n    BatchNormalization(),\n    Dropout(0.25),\n    ReLU(),\n    Conv2D(64,kernel_size=(2,2)),\n    ReLU(),\n    AveragePooling2D(pool_size=2,strides=(2,2)),\n    Conv2D(64,kernel_size=(2,2),padding='same'),\n    BatchNormalization(),\n    Dropout(0.25),\n    AveragePooling2D(pool_size=2,strides=(2,2)),\n    ReLU(),\n    Conv2D(128,kernel_size=(2,2),padding='same'),\n    BatchNormalization(),\n    ReLU(),\n    Dropout(0.5),\n    Conv2D(64,kernel_size=(3,3),padding='same'),\n    AveragePooling2D(pool_size=2,strides=(2,2)),\n    Dropout(0.25),\n    ReLU(),\n    Conv2D(32,kernel_size=(2,2),padding='same'),\n    Conv2D(32,kernel_size=(3,3),padding='same'),\n    BatchNormalization(),\n    ReLU(),\n    GlobalAveragePooling2D(),\n    Flatten(),\n    Dense(1200,activation='tanh'),\n    BatchNormalization(),\n    Dropout(0.25),\n    Dense(500,activation='tanh'),\n    #Dense(800,activation='relu'),\n    BatchNormalization(),\n    Dropout(0.25),\n    Dense(38,activation='softmax'),\n])\n'''\nclass plantmodel(nn.Module):\n  def __init__(self):\n    super(plantmodel,self).__init__()\n    self.cnnmodel=nn.Sequential(\n        nn.Conv2d(3,6,kernel_size=(2,2)),\n        nn.AvgPool2d(2,stride=2),\n        nn.BatchNorm2d(6),\n        nn.Dropout2d(0.25),\n        nn.ReLU(),\n        nn.Conv2d(6,16,kernel_size=(2,2)),\n        nn.BatchNorm2d(16),\n        nn.AvgPool2d(2,stride=2),\n        nn.Dropout2d(0.25),\n        nn.ReLU(),\n        nn.Conv2d(16,24,kernel_size=(3,3)),\n        nn.AvgPool2d(2,stride=2),\n        nn.BatchNorm2d(24),\n        nn.Dropout2d(0.5),\n        nn.ReLU(),\n        nn.Conv2d(24,20,kernel_size=(2,2)),\n        nn.BatchNorm2d(20),\n        nn.Dropout2d(0.25),\n        nn.ReLU(),\n        nn.Conv2d(20,32,kernel_size=(2,2)),\n        nn.AvgPool2d(2,stride=2),\n        nn.BatchNorm2d(32),\n        nn.Dropout2d(0.25),\n        nn.ReLU(),\n        nn.Conv2d(32,16,kernel_size=(3,3)),\n        nn.AvgPool2d(2,stride=2),\n        nn.BatchNorm2d(16),\n        nn.Dropout2d(0.5),\n        nn.ReLU()\n    )\n    self.ffnmodel=nn.Sequential(\n        nn.Linear(1296,1000),\n        nn.BatchNorm1d(1000),\n        nn.Dropout(0.5),\n        nn.Tanh(),\n        nn.Linear(1000,800),\n        nn.BatchNorm1d(800),\n        nn.Dropout(0.5),\n        nn.Tanh(),\n        nn.Linear(800,400),\n        nn.BatchNorm1d(400),\n        nn.Dropout(0.5),\n        nn.Tanh(),\n        nn.Linear(400,200),\n        nn.BatchNorm1d(200),\n        nn.Dropout(0.5),\n        nn.Tanh(),\n        nn.Linear(200,38)\n    )\n  def forward(self,x):\n    x=self.cnnmodel(x)\n    x=x.view(x.size(0),-1)\n    x=self.ffnmodel(x)\n    return x\n    \n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n                              factor=0.4, \n                              patience=2, \n                              verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath='./output/checkpoint',\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='min',\n    save_best_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=700\nhist = model.fit(x=training_set,\n                  batch_size=batch_size,\n                 validation_data=val_set,\n                 epochs=30,\n                 callbacks=[reduce_lr,model_checkpoint_callback],\n                 steps_per_epoch = training_set.n//batch_size ,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testx=[]\ntesty=[]\nfor i in range(10):\n    a,b=val_set.next()\n    print(a.shape)\n    testx.append(a)\n    testy.append(b)\ntestx=np.asarray(testx)\ntesty=np.asarray(testy)\nprint(testx.shape)\nprint(testy.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testx=np.reshape(testx,(-1,128,128,3))\ntesty=np.reshape(testy,(-1,38))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(testx.shape)\nprint(testy.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./output/checkpoint')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=np.argmax(model.predict(testx),axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir -p saved_model\nmodel.save('saved_model/my_model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('plant_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c=0\nfor i in range(len(y_pred)):\n    if y_pred[i]==np.argmax(testy[i]):\n        c+=1\nprint(c/1280)\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=128\nhist = model2.fit(x=training_set,\n                  batch_size=batch_size,\n                 validation_data=val_set,\n                 epochs=1,\n                 callbacks=reduce_lr,\n                 steps_per_epoch = training_set.n//batch_size ,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_output=model2.predict(test_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_names=training_set.class_indices\nindex={}\nfor key,value in index_names.items():\n    index[value]=key\nindex","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_op=np.argmax(np.asarray(test_output),axis=1)\ntest_op","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plant_names=[]\nfor k in test_op:\n    plant_names.append(index[k])\nprint(plant_names)\nprint()\nprint(index_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c=0\nfor i in range(len(test_labels)):\n    s=plant_names[i].replace(\"_\",\"\")\n    if s.lower()==test_labels[i].lower():\n        c+=1\nprint(\"Test Accuracy {:.2f}\".format(c/len(test_labels)))       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2.save('..output/kaggle/working/final_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_outputs = [layer.output for layer in base_model2.layers[20:40]]\nactivation_model = models.Model(inputs=base_model2.input, outputs=layer_outputs) \nactivations = activation_model.predict(test_set[0:1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(\n    base_model2, to_file='model.png', show_shapes=True,\n    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=96\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_names = []\nclassifier=base_model2\nfor layer in classifier.layers[20:40]:\n    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n    \nimages_per_row = 16\nfor layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n    n_features = layer_activation.shape[-1] # Number of features in the feature map\n    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    for col in range(n_cols): # Tiles each filter into a big horizontal grid\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n            channel_image /= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size, # Displays the grid\n                         row * size : (row + 1) * size] = channel_image\n    scale = 1. / size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set[0:1].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_set.class_indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}